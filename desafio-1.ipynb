{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","['muchas', 'dia', 'es', 'gracias', 'de', 'que', 'hoy', 'el', 'martes']\n"]}],"source":["# Prompt ChatGPT con model gpt-4:\n","#\n","# Como precondicion, se tiene el siguiente corpus:\n","# ```\n","# corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","# ```\n","# Se define la siguiente consigna:\n","# ```\n","# ### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","# - Cada documento transformarlo en una lista de términos\n","# - Armar un vector de términos no repetidos de todos los documentos\n","# ```\n","# Dar solucion en codigo python para ser ejecutado en Google Colab\n","\n","# Transformar cada documento en una lista de términos\n","corpus_terms = [doc.split() for doc in corpus]\n","\n","print(corpus_terms)\n","\n","# Aplanar la lista de listas y eliminar términos repetidos\n","vocabulario = list(set([term for sublist in corpus_terms for term in sublist]))\n","\n","print(vocabulario)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Dada una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 1 0 1 0 1 0 0 1]\n"," [1 1 1 1 0 1 1 0 0]\n"," [0 0 0 0 1 0 1 1 0]]\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Realizar una funcion que dada una lista de textos, devolver una matriz con la representación oneHotEncoding de estos\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","def one_hot_encoding(textos):\n","    # Creamos un objeto CountVectorizer y lo ajustamos a nuestros textos\n","    vectorizer = CountVectorizer(binary=True)  # binary=True para obtener una representación OneHot\n","    X = vectorizer.fit_transform(textos)\n","\n","    # Convertimos la matriz dispersa resultante en una matriz densa\n","    one_hot_matrix = X.toarray()\n","\n","    return one_hot_matrix\n","\n","# Probamos la función\n","print(one_hot_encoding(corpus))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Dada una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 1 0 1 0 1 0 0 1]\n"," [1 1 1 1 0 1 2 0 0]\n"," [0 0 0 0 1 0 1 1 0]]\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Realizar una funcion para la siguiente consigna:\n","#\n","# ```\n","# ### 3- Vectores de frecuencia\n","# Dada una lista de textos, devolver una matriz con la representación de frecuencia de estos\n","# ```\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","def frequency_vectors(textos):\n","    # Creamos un objeto CountVectorizer\n","    vectorizer = CountVectorizer()\n","\n","    # Ajustamos y transformamos nuestros textos\n","    X = vectorizer.fit_transform(textos)\n","\n","    # Convertimos la matriz dispersa resultante en una matriz densa\n","    frequency_matrix = X.toarray()\n","\n","    return frequency_matrix\n","\n","# Probamos la función\n","print(frequency_vectors(corpus))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Dada una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.         0.45985353 0.         0.45985353 0.         0.45985353\n","  0.         0.         0.60465213]\n"," [0.40659827 0.30922846 0.40659827 0.30922846 0.         0.30922846\n","  0.61845693 0.         0.        ]\n"," [0.         0.         0.         0.         0.62276601 0.\n","  0.4736296  0.62276601 0.        ]]\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Realizar una funcion para la siguiente consigna:\n","#\n","# ### 4- TF-IDF\n","# Dada una lista de textos, devolver una matriz con la representacion TFIDF\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","def tfidf_vectors(textos):\n","    # Creamos un objeto TfidfVectorizer\n","    vectorizer = TfidfVectorizer()\n","\n","    # Ajustamos y transformamos nuestros textos\n","    X = vectorizer.fit_transform(textos)\n","\n","    # Convertimos la matriz dispersa resultante en una matriz densa\n","    tfidf_matrix = X.toarray()\n","\n","    return tfidf_matrix\n","\n","# Probamos la función\n","print(tfidf_vectors(corpus))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Documento:  que dia es hoy , Documentos ordenados por similitud: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","Documento:  martes el dia de hoy es martes , Documentos ordenados por similitud: ['martes el dia de hoy es martes' 'que dia es hoy' 'martes muchas gracias']\n","Documento:  martes muchas gracias , Documentos ordenados por similitud: ['martes muchas gracias' 'martes el dia de hoy es martes' 'que dia es hoy']\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Se tiene definida la siguiente funcion:\n","#\n","# ```\n","# def cosine_similarity(a, b):\n","#     return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))\n","# ```\n","#\n","# Se tiene la siguiente consigna:\n","#\n","# ```\n","# ### 5 - Comparación de documentos\n","# Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno\n","# ```\n","\n","def compare_documents(corpus, index):\n","    # Obtener los vectores tf-idf del corpus\n","    vectors = tfidf_vectors(corpus)\n","    \n","    # Obtener el vector del documento de interés\n","    doc_vector = vectors[index]\n","    \n","    # Calcular la similitud coseno entre el documento de interés y cada documento en el corpus\n","    similarities = [cosine_similarity(doc_vector, vector) for vector in vectors]\n","    \n","    # Ordenar los índices de los documentos en el corpus por su similitud con el documento de interés\n","    sorted_indices = np.argsort(similarities)[::-1]\n","    \n","    # Devolver los documentos ordenados por similitud\n","    return corpus[sorted_indices]\n","\n","# Probamos la función\n","for i in range(0, len(corpus)):\n","    print( \"Documento: \", corpus[i], \", Documentos ordenados por similitud:\", compare_documents(corpus, i))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
