{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"pfa39F4lsLf3"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## LSTM Bot QA"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Ejercicio\n","\n","Construir QA Bot basado en el ejemplo del traductor pero con un dataset QA.\n","\n","Recomendaciones:\n","- MAX_VOCAB_SIZE = 8000\n","- max_length ~ 10\n","- Embeddings 300 Fasttext\n","- n_units = 128\n","- LSTM Dropout 0.2\n","- Epochs 30~50\n","\n","Preguntas interesantes:\n","- Do you read?\n","- Do you have any pet?\n","- Where are you from?\n","\n","__IMPORTANTE__: Recuerde para la entrega del ejercicio debe quedar registrado en el colab las preguntas y las respuestas del BOT para que podamos evaluar el desempeño final.\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZqO0PRcFsPTe"},"source":["### Datos\n","El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n","[LINK](http://convai.io/data/)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"bDFC0I3j9oFD"},"outputs":[],"source":["#!pip install --upgrade --no-cache-dir gdown --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: /home/jonathan/anaconda3/envs/tf-wsl2/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n","Python 3.11.3\n"]}],"source":["!python -V"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-05 00:45:40.814027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-05 00:45:42.023100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 1947897506867743575\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 9289334784\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 4462959085884492047\n","physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n","]\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-05 00:45:43.808983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:43.846298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:43.846347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:45.183691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:45.183767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:45.183775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2023-06-05 00:45:45.183807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:45.183830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 8859 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"]}],"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cq3YXak9sGHd"},"outputs":[],"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from keras.preprocessing.text import one_hot\n","from tensorflow.keras.utils import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM, SimpleRNN\n","from keras.models import Model\n","from tensorflow.keras.layers import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RHNkUaPp6aYq"},"outputs":[{"name":"stdout","output_type":"stream","text":["El dataset ya se encuentra descargado\n"]}],"source":["# Descargar la carpeta de dataset\n","import os\n","import gdown\n","if os.access('data_volunteers.json', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n","    output = 'data_volunteers.json'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"WZy1-wgG-Rp7"},"outputs":[],"source":["# dataset_file\n","import json\n","\n","text_file = \"data_volunteers.json\"\n","with open(text_file) as f:\n","    data = json.load(f) # la variable data será un diccionario\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ue5qd54S-eew"},"outputs":[{"data":{"text/plain":["dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Observar los campos disponibles en cada linea del dataset\n","data[0].keys()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"jHBRAXPl-3dz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de rows utilizadas: 1903\n"]}],"source":["chat_in = []\n","chat_out = []\n","\n","input_sentences = []\n","output_sentences = []\n","output_sentences_inputs = []\n","max_len = 20\n","\n","def clean_text(txt):\n","    txt = txt.lower()    \n","    txt.replace(\"\\'d\", \" had\")\n","    txt.replace(\"\\'s\", \" is\")\n","    txt.replace(\"\\'m\", \" am\")\n","    txt.replace(\"don't\", \"do not\")\n","    txt = re.sub(r'\\W+', ' ', txt)\n","    \n","    return txt\n","\n","for line in data:\n","    for i in range(len(line['dialog'])-1):\n","        # vamos separando el texto en \"preguntas\" (chat_in)\n","        # y \"respuestas\" (chat_out)\n","        chat_in = clean_text(line['dialog'][i]['text'])\n","        chat_out = clean_text(line['dialog'][i+1]['text'])\n","\n","        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n","            continue\n","\n","        input_sentence, output = chat_in, chat_out\n","        \n","        # output sentence (decoder_output) tiene <eos>\n","        output_sentence = output + ' <eos>'\n","        # output sentence input (decoder_input) tiene <sos>\n","        output_sentence_input = '<sos> ' + output\n","\n","        input_sentences.append(input_sentence)\n","        output_sentences.append(output_sentence)\n","        output_sentences_inputs.append(output_sentence_input)\n","\n","print(\"Cantidad de rows utilizadas:\", len(input_sentences))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"07L1qj8pC_l6"},"outputs":[{"data":{"text/plain":["('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["input_sentences[1], output_sentences[1], output_sentences_inputs[1]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8P-ynUNP5xp6"},"source":["### 2 - Preprocesamiento\n","Realizar el preprocesamiento necesario para obtener:\n","- word2idx_inputs, max_input_len\n","- word2idx_outputs, max_out_len, num_words_output\n","- encoder_input_sequences, decoder_output_sequences, decoder_targets"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Definir el tamaño máximo del vocabulario\n","MAX_VOCAB_SIZE = 8000"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Palabras en el vocabulario: 752\n","Sentencia de entrada más larga: 7\n"]}],"source":["# Tokenizar las palabras con el Tokenizer de Keras\n","# Definir una máxima cantidad de palabras a utilizar:\n","# - num_words --> the maximum number of words to keep, based on word frequency.\n","# - Only the most common num_words-1 words will be kept.\n","from keras.preprocessing.text import Tokenizer\n","\n","# tokenizador de inglés\n","input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n","input_tokenizer.fit_on_texts(input_sentences)\n","input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n","\n","word2idx_inputs = input_tokenizer.word_index\n","print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n","\n","max_input_len = max(len(sen) for sen in input_integer_seq)\n","print(\"Sentencia de entrada más larga:\", max_input_len)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Palabras en el vocabulario: 714\n","Sentencia de salida más larga: 7\n"]}],"source":["# tokenizador de español\n","# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n","# sacamos los \"<>\" para que no afectar nuestros tokens\n","output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n","output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n","output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n","output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n","\n","word2idx_outputs = output_tokenizer.word_index\n","print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n","\n","num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) \n","# Se suma 1 para incluir el token de palabra desconocida\n","\n","max_out_len = max(len(sen) for sen in output_integer_seq)\n","print(\"Sentencia de salida más larga:\", max_out_len)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de rows del dataset: 1903\n","encoder_input_sequences shape: (1903, 7)\n","decoder_input_sequences shape: (1903, 7)\n"]}],"source":["print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n","\n","encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n","print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n","\n","decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n","print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["(1903, 7, 715)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["from keras.utils.np_utils import to_categorical\n","decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n","decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n","decoder_targets.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_CJIsLBbj6rg"},"source":["### 3 - Preparar los embeddings\n","Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El dataset ya se encuentra descargado\n"]}],"source":["# Descargar los embeddings desde un google drive (es la forma más rápida)\n","# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n","# disponibles descargar de la página oficial como se explica en el siguiente bloque de código\n","import os\n","import gdown\n","if os.access('fasttext.pkl', os.F_OK) is False:\n","    url = 'https://drive.google.com/u/0/uc?id=1Qi1r-u5lsEsNqRSxLrpNOqQ3B_ufltCa&export=download&confirm=t'\n","    output = 'fasttext.pkl'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import logging\n","import os\n","from pathlib import Path\n","from io import StringIO\n","import pickle\n","\n","class WordsEmbeddings(object):\n","    logger = logging.getLogger(__name__)\n","\n","    def __init__(self):\n","        # load the embeddings\n","        words_embedding_pkl = Path(self.PKL_PATH)\n","        if not words_embedding_pkl.is_file():\n","            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n","            assert words_embedding_txt.is_file(), 'Words embedding not available'\n","            embeddings = self.convert_model_to_pickle()\n","        else:\n","            embeddings = self.load_model_from_pickle()\n","        self.embeddings = embeddings\n","        # build the vocabulary hashmap\n","        index = np.arange(self.embeddings.shape[0])\n","        # Dicctionarios para traducir de embedding a IDX de la palabra\n","        self.word2idx = dict(zip(self.embeddings['word'], index))\n","        self.idx2word = dict(zip(index, self.embeddings['word']))\n","\n","    def get_words_embeddings(self, words):\n","        words_idxs = self.words2idxs(words)\n","        return self.embeddings[words_idxs]['embedding']\n","\n","    def words2idxs(self, words):\n","        return np.array([self.word2idx.get(word, -1) for word in words])\n","\n","    def idxs2words(self, idxs):\n","        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n","\n","    def load_model_from_pickle(self):\n","        self.logger.debug(\n","            'loading words embeddings from pickle {}'.format(\n","                self.PKL_PATH\n","            )\n","        )\n","        max_bytes = 2**28 - 1 # 256MB\n","        bytes_in = bytearray(0)\n","        input_size = os.path.getsize(self.PKL_PATH)\n","        with open(self.PKL_PATH, 'rb') as f_in:\n","            for _ in range(0, input_size, max_bytes):\n","                bytes_in += f_in.read(max_bytes)\n","        embeddings = pickle.loads(bytes_in)\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","    def convert_model_to_pickle(self):\n","        # create a numpy strctured array:\n","        # word     embedding\n","        # U50      np.float32[]\n","        # word_1   a, b, c\n","        # word_2   d, e, f\n","        # ...\n","        # word_n   g, h, i\n","        self.logger.debug(\n","            'converting and loading words embeddings from text file {}'.format(\n","                self.WORD_TO_VEC_MODEL_TXT_PATH\n","            )\n","        )\n","        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n","                     ('embedding', np.float32, (self.N_FEATURES,))]\n","        structure = np.dtype(structure)\n","        # load numpy array from disk using a generator\n","        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n","            embeddings_gen = (\n","                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n","                if len(line.split()[1:]) == self.N_FEATURES\n","            )\n","            embeddings = np.fromiter(embeddings_gen, structure)\n","        # add a null embedding\n","        null_embedding = np.array(\n","            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n","            dtype=structure\n","        )\n","        embeddings = np.concatenate([embeddings, null_embedding])\n","        # dump numpy array to disk using pickle\n","        max_bytes = 2**28 - 1 # # 256MB\n","        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n","        with open(self.PKL_PATH, 'wb') as f_out:\n","            for idx in range(0, len(bytes_out), max_bytes):\n","                f_out.write(bytes_out[idx:idx+max_bytes])\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","\n","class GloveEmbeddings(WordsEmbeddings):\n","    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n","    PKL_PATH = 'gloveembedding.pkl'\n","    N_FEATURES = 50\n","    WORD_MAX_SIZE = 60\n","\n","class FasttextEmbeddings(WordsEmbeddings):\n","    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n","    PKL_PATH = 'fasttext.pkl'\n","    N_FEATURES = 300\n","    WORD_MAX_SIZE = 60"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Por una cuestion de RAM se utilizarán los embeddings de Glove de dimension 50\n","model_embeddings = FasttextEmbeddings()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["preparing embedding matrix...\n","number of null word embeddings: 1\n"]}],"source":["# Crear la Embedding matrix de las secuencias\n","# en inglés\n","\n","print('preparing embedding matrix...')\n","embed_dim = model_embeddings.N_FEATURES\n","words_not_found = []\n","\n","# word_index provieen del tokenizer\n","\n","nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n","embedding_matrix = np.zeros((nb_words, embed_dim))\n","for word, i in word2idx_inputs.items():\n","    if i >= nb_words:\n","        continue\n","    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n","    if (embedding_vector is not None) and len(embedding_vector) > 0:\n","        \n","        embedding_matrix[i] = embedding_vector\n","    else:\n","        # words not found in embedding index will be all-zeros.\n","        words_not_found.append(word)\n","\n","print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["(752, 300)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Dimensión de los embeddings de la secuencia en inglés\n","embedding_matrix.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3vKbhjtIwPgM"},"source":["### 4 - Entrenar el modelo\n","Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["7"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["max_input_len"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-05 00:45:58.162332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.165122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.165165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.184086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.184147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.184176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.206075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.206098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2023-06-05 00:45:58.206142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-05 00:45:58.206164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8859 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n","2023-06-05 00:46:00.422065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:00.423430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:00.424254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-06-05 00:46:00.620054: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:00.621138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:00.622116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 7)]          0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 7)]          0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 7, 300)       225600      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 7, 128)       91520       ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 128),        219648      ['embedding[0][0]']              \n","                                 (None, 128),                                                     \n","                                 (None, 128)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 7, 128),     131584      ['embedding_1[0][0]',            \n","                                 (None, 128),                     'lstm[0][1]',                   \n","                                 (None, 128)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 7, 715)       92235       ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 760,587\n","Trainable params: 534,987\n","Non-trainable params: 225,600\n","__________________________________________________________________________________________________\n"]}],"source":["from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","\n","n_units = 128\n","dropout_rate = 0.2\n","\n","# define training encoder\n","encoder_inputs = Input(shape=(max_input_len))\n","\n","#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n","\n","encoder_embedding_layer = Embedding(\n","          input_dim=nb_words,  # definido en el Tokenizador\n","          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n","          input_length=max_input_len, # tamaño máximo de la secuencia de entrada\n","          weights=[embedding_matrix],  # matrix de embeddings\n","          trainable=False)      # marcar como layer no entrenable\n","\n","encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n","\n","encoder = LSTM(n_units, return_state=True, dropout=dropout_rate)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n","encoder_states = [state_h, state_c]\n","\n","# define training decoder\n","decoder_inputs = Input(shape=(max_out_len))\n","decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n","decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n","\n","decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, dropout=dropout_rate)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n","\n","# Dense\n","decoder_dense = Dense(num_words_output, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"]}],"source":["# Modelo completo (encoder+decoder) para poder entrenar\n","from keras.utils.vis_utils import plot_model\n","plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"]}],"source":["# Modelo solo encoder\n","\n","# define inference encoder\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","from keras.utils.vis_utils import plot_model\n","plot_model(encoder_model, to_file='encoder_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-05 00:46:01.145320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:01.146937: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:01.147876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"]}],"source":["# Modelo solo decoder (para realizar inferencia)\n","from keras.utils.vis_utils import plot_model\n","\n","# define inference decoder\n","decoder_state_input_h = Input(shape=(n_units,))\n","decoder_state_input_c = Input(shape=(n_units,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# En cada predicción habrá una sola palabra de entrada al decoder,\n","# que es la realimentación de la palabra anterior\n","# por lo que hay que modificar el input shape de la layer de Embedding\n","decoder_inputs_single = Input(shape=(1,))\n","decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n","\n","plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-05 00:46:02.947243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:02.948921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:02.950070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-06-05 00:46:03.121679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:03.123050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:03.124169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-06-05 00:46:04.136513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:04.138136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:04.139151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-06-05 00:46:04.299519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:04.300639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:04.301802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-06-05 00:46:11.218676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n","2023-06-05 00:46:11.573623: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc1a6293ea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-06-05 00:46:11.573673: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n","2023-06-05 00:46:11.669318: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-06-05 00:46:12.155998: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","2023-06-05 00:46:12.311725: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["48/48 [==============================] - ETA: 0s - loss: 3.8295 - accuracy: 0.4558"]},{"name":"stderr","output_type":"stream","text":["2023-06-05 00:46:16.328041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:16.329316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:16.330672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-06-05 00:46:16.503849: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-06-05 00:46:16.505308: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-06-05 00:46:16.506446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"]},{"name":"stdout","output_type":"stream","text":["48/48 [==============================] - 15s 83ms/step - loss: 3.8295 - accuracy: 0.4558 - val_loss: 2.8052 - val_accuracy: 0.4829\n","Epoch 2/150\n","48/48 [==============================] - 1s 21ms/step - loss: 2.3992 - accuracy: 0.5206 - val_loss: 2.4848 - val_accuracy: 0.5917\n","Epoch 3/150\n","48/48 [==============================] - 1s 24ms/step - loss: 2.1234 - accuracy: 0.6271 - val_loss: 2.3422 - val_accuracy: 0.6273\n","Epoch 4/150\n","48/48 [==============================] - 1s 16ms/step - loss: 1.9858 - accuracy: 0.6387 - val_loss: 2.2692 - val_accuracy: 0.6307\n","Epoch 5/150\n","48/48 [==============================] - 1s 16ms/step - loss: 1.8796 - accuracy: 0.6502 - val_loss: 2.2181 - val_accuracy: 0.6397\n","Epoch 6/150\n","48/48 [==============================] - 1s 19ms/step - loss: 1.7576 - accuracy: 0.6827 - val_loss: 2.1564 - val_accuracy: 0.6625\n","Epoch 7/150\n","48/48 [==============================] - 1s 17ms/step - loss: 1.6395 - accuracy: 0.7156 - val_loss: 2.1049 - val_accuracy: 0.6663\n","Epoch 8/150\n","48/48 [==============================] - 1s 17ms/step - loss: 1.5570 - accuracy: 0.7216 - val_loss: 2.0714 - val_accuracy: 0.6682\n","Epoch 9/150\n","48/48 [==============================] - 1s 17ms/step - loss: 1.5012 - accuracy: 0.7241 - val_loss: 2.0582 - val_accuracy: 0.6689\n","Epoch 10/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.4636 - accuracy: 0.7271 - val_loss: 2.0479 - val_accuracy: 0.6704\n","Epoch 11/150\n","48/48 [==============================] - 1s 16ms/step - loss: 1.4306 - accuracy: 0.7353 - val_loss: 2.0285 - val_accuracy: 0.6779\n","Epoch 12/150\n","48/48 [==============================] - 1s 19ms/step - loss: 1.4024 - accuracy: 0.7388 - val_loss: 2.0188 - val_accuracy: 0.6772\n","Epoch 13/150\n","48/48 [==============================] - 1s 19ms/step - loss: 1.3752 - accuracy: 0.7381 - val_loss: 2.0120 - val_accuracy: 0.6787\n","Epoch 14/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.3514 - accuracy: 0.7396 - val_loss: 2.0053 - val_accuracy: 0.6805\n","Epoch 15/150\n","48/48 [==============================] - 1s 17ms/step - loss: 1.3271 - accuracy: 0.7420 - val_loss: 2.0008 - val_accuracy: 0.6817\n","Epoch 16/150\n","48/48 [==============================] - 1s 17ms/step - loss: 1.3064 - accuracy: 0.7436 - val_loss: 1.9957 - val_accuracy: 0.6835\n","Epoch 17/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.2885 - accuracy: 0.7454 - val_loss: 1.9972 - val_accuracy: 0.6835\n","Epoch 18/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.2726 - accuracy: 0.7482 - val_loss: 1.9958 - val_accuracy: 0.6850\n","Epoch 19/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.2546 - accuracy: 0.7479 - val_loss: 1.9993 - val_accuracy: 0.6847\n","Epoch 20/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.2389 - accuracy: 0.7488 - val_loss: 1.9961 - val_accuracy: 0.6843\n","Epoch 21/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.2251 - accuracy: 0.7494 - val_loss: 1.9994 - val_accuracy: 0.6865\n","Epoch 22/150\n","48/48 [==============================] - 1s 15ms/step - loss: 1.2096 - accuracy: 0.7521 - val_loss: 2.0026 - val_accuracy: 0.6850\n","Epoch 23/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1954 - accuracy: 0.7525 - val_loss: 2.0034 - val_accuracy: 0.6854\n","Epoch 24/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1821 - accuracy: 0.7559 - val_loss: 2.0169 - val_accuracy: 0.6862\n","Epoch 25/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1705 - accuracy: 0.7554 - val_loss: 2.0143 - val_accuracy: 0.6877\n","Epoch 26/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1563 - accuracy: 0.7562 - val_loss: 2.0100 - val_accuracy: 0.6895\n","Epoch 27/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1433 - accuracy: 0.7587 - val_loss: 2.0170 - val_accuracy: 0.6873\n","Epoch 28/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1306 - accuracy: 0.7613 - val_loss: 2.0208 - val_accuracy: 0.6918\n","Epoch 29/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1186 - accuracy: 0.7601 - val_loss: 2.0174 - val_accuracy: 0.6910\n","Epoch 30/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.1061 - accuracy: 0.7629 - val_loss: 2.0219 - val_accuracy: 0.6929\n","Epoch 31/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.0920 - accuracy: 0.7625 - val_loss: 2.0386 - val_accuracy: 0.6918\n","Epoch 32/150\n","48/48 [==============================] - 1s 16ms/step - loss: 1.0811 - accuracy: 0.7647 - val_loss: 2.0352 - val_accuracy: 0.6907\n","Epoch 33/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.0694 - accuracy: 0.7652 - val_loss: 2.0309 - val_accuracy: 0.6925\n","Epoch 34/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.0562 - accuracy: 0.7667 - val_loss: 2.0399 - val_accuracy: 0.6918\n","Epoch 35/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.0442 - accuracy: 0.7690 - val_loss: 2.0435 - val_accuracy: 0.6918\n","Epoch 36/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.0319 - accuracy: 0.7687 - val_loss: 2.0550 - val_accuracy: 0.6918\n","Epoch 37/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.0196 - accuracy: 0.7679 - val_loss: 2.0537 - val_accuracy: 0.6925\n","Epoch 38/150\n","48/48 [==============================] - 1s 14ms/step - loss: 1.0079 - accuracy: 0.7714 - val_loss: 2.0597 - val_accuracy: 0.6929\n","Epoch 39/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.9975 - accuracy: 0.7728 - val_loss: 2.0634 - val_accuracy: 0.6937\n","Epoch 40/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9867 - accuracy: 0.7740 - val_loss: 2.0619 - val_accuracy: 0.6929\n","Epoch 41/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9739 - accuracy: 0.7757 - val_loss: 2.0682 - val_accuracy: 0.6914\n","Epoch 42/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9649 - accuracy: 0.7770 - val_loss: 2.0883 - val_accuracy: 0.6914\n","Epoch 43/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9544 - accuracy: 0.7785 - val_loss: 2.0843 - val_accuracy: 0.6922\n","Epoch 44/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9421 - accuracy: 0.7800 - val_loss: 2.0934 - val_accuracy: 0.6914\n","Epoch 45/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9297 - accuracy: 0.7822 - val_loss: 2.0907 - val_accuracy: 0.6922\n","Epoch 46/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9208 - accuracy: 0.7825 - val_loss: 2.1014 - val_accuracy: 0.6925\n","Epoch 47/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9092 - accuracy: 0.7866 - val_loss: 2.1041 - val_accuracy: 0.6910\n","Epoch 48/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.9013 - accuracy: 0.7878 - val_loss: 2.1108 - val_accuracy: 0.6922\n","Epoch 49/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8903 - accuracy: 0.7886 - val_loss: 2.1127 - val_accuracy: 0.6873\n","Epoch 50/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8800 - accuracy: 0.7916 - val_loss: 2.1237 - val_accuracy: 0.6888\n","Epoch 51/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8702 - accuracy: 0.7928 - val_loss: 2.1319 - val_accuracy: 0.6922\n","Epoch 52/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8617 - accuracy: 0.7936 - val_loss: 2.1323 - val_accuracy: 0.6888\n","Epoch 53/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8521 - accuracy: 0.7970 - val_loss: 2.1404 - val_accuracy: 0.6914\n","Epoch 54/150\n","48/48 [==============================] - 1s 17ms/step - loss: 0.8437 - accuracy: 0.7964 - val_loss: 2.1388 - val_accuracy: 0.6865\n","Epoch 55/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8341 - accuracy: 0.7996 - val_loss: 2.1529 - val_accuracy: 0.6907\n","Epoch 56/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8254 - accuracy: 0.7994 - val_loss: 2.1544 - val_accuracy: 0.6895\n","Epoch 57/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8172 - accuracy: 0.8028 - val_loss: 2.1641 - val_accuracy: 0.6895\n","Epoch 58/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8089 - accuracy: 0.8033 - val_loss: 2.1654 - val_accuracy: 0.6854\n","Epoch 59/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.8003 - accuracy: 0.8045 - val_loss: 2.1774 - val_accuracy: 0.6862\n","Epoch 60/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.7922 - accuracy: 0.8062 - val_loss: 2.1729 - val_accuracy: 0.6843\n","Epoch 61/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7860 - accuracy: 0.8072 - val_loss: 2.1759 - val_accuracy: 0.6865\n","Epoch 62/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7767 - accuracy: 0.8087 - val_loss: 2.1863 - val_accuracy: 0.6854\n","Epoch 63/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.7704 - accuracy: 0.8092 - val_loss: 2.1973 - val_accuracy: 0.6869\n","Epoch 64/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7620 - accuracy: 0.8123 - val_loss: 2.2020 - val_accuracy: 0.6892\n","Epoch 65/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7550 - accuracy: 0.8141 - val_loss: 2.2052 - val_accuracy: 0.6877\n","Epoch 66/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7485 - accuracy: 0.8126 - val_loss: 2.2048 - val_accuracy: 0.6820\n","Epoch 67/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.7419 - accuracy: 0.8167 - val_loss: 2.2171 - val_accuracy: 0.6854\n","Epoch 68/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7329 - accuracy: 0.8178 - val_loss: 2.2183 - val_accuracy: 0.6843\n","Epoch 69/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7251 - accuracy: 0.8185 - val_loss: 2.2248 - val_accuracy: 0.6888\n","Epoch 70/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7192 - accuracy: 0.8214 - val_loss: 2.2351 - val_accuracy: 0.6854\n","Epoch 71/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7152 - accuracy: 0.8205 - val_loss: 2.2341 - val_accuracy: 0.6820\n","Epoch 72/150\n","48/48 [==============================] - 1s 17ms/step - loss: 0.7081 - accuracy: 0.8216 - val_loss: 2.2488 - val_accuracy: 0.6862\n","Epoch 73/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.7013 - accuracy: 0.8232 - val_loss: 2.2546 - val_accuracy: 0.6843\n","Epoch 74/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6937 - accuracy: 0.8247 - val_loss: 2.2606 - val_accuracy: 0.6835\n","Epoch 75/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.6884 - accuracy: 0.8258 - val_loss: 2.2642 - val_accuracy: 0.6798\n","Epoch 76/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.6828 - accuracy: 0.8272 - val_loss: 2.2728 - val_accuracy: 0.6828\n","Epoch 77/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6758 - accuracy: 0.8287 - val_loss: 2.2748 - val_accuracy: 0.6847\n","Epoch 78/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6693 - accuracy: 0.8291 - val_loss: 2.2888 - val_accuracy: 0.6828\n","Epoch 79/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.6636 - accuracy: 0.8292 - val_loss: 2.2892 - val_accuracy: 0.6839\n","Epoch 80/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.6584 - accuracy: 0.8323 - val_loss: 2.2961 - val_accuracy: 0.6869\n","Epoch 81/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.6534 - accuracy: 0.8345 - val_loss: 2.3056 - val_accuracy: 0.6832\n","Epoch 82/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6472 - accuracy: 0.8335 - val_loss: 2.3091 - val_accuracy: 0.6880\n","Epoch 83/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6441 - accuracy: 0.8349 - val_loss: 2.3157 - val_accuracy: 0.6817\n","Epoch 84/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6365 - accuracy: 0.8369 - val_loss: 2.3262 - val_accuracy: 0.6817\n","Epoch 85/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6314 - accuracy: 0.8346 - val_loss: 2.3270 - val_accuracy: 0.6794\n","Epoch 86/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.6252 - accuracy: 0.8372 - val_loss: 2.3282 - val_accuracy: 0.6809\n","Epoch 87/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6202 - accuracy: 0.8379 - val_loss: 2.3350 - val_accuracy: 0.6783\n","Epoch 88/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.6168 - accuracy: 0.8395 - val_loss: 2.3393 - val_accuracy: 0.6824\n","Epoch 89/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.6081 - accuracy: 0.8413 - val_loss: 2.3524 - val_accuracy: 0.6824\n","Epoch 90/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.6057 - accuracy: 0.8414 - val_loss: 2.3533 - val_accuracy: 0.6798\n","Epoch 91/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.5969 - accuracy: 0.8468 - val_loss: 2.3689 - val_accuracy: 0.6805\n","Epoch 92/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5937 - accuracy: 0.8450 - val_loss: 2.3695 - val_accuracy: 0.6783\n","Epoch 93/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.5892 - accuracy: 0.8477 - val_loss: 2.3752 - val_accuracy: 0.6798\n","Epoch 94/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.5846 - accuracy: 0.8480 - val_loss: 2.3842 - val_accuracy: 0.6768\n","Epoch 95/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5797 - accuracy: 0.8489 - val_loss: 2.3905 - val_accuracy: 0.6757\n","Epoch 96/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5729 - accuracy: 0.8500 - val_loss: 2.3907 - val_accuracy: 0.6783\n","Epoch 97/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.5684 - accuracy: 0.8524 - val_loss: 2.4038 - val_accuracy: 0.6790\n","Epoch 98/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5610 - accuracy: 0.8555 - val_loss: 2.4130 - val_accuracy: 0.6798\n","Epoch 99/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5601 - accuracy: 0.8537 - val_loss: 2.4144 - val_accuracy: 0.6790\n","Epoch 100/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5544 - accuracy: 0.8567 - val_loss: 2.4188 - val_accuracy: 0.6779\n","Epoch 101/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5491 - accuracy: 0.8576 - val_loss: 2.4135 - val_accuracy: 0.6742\n","Epoch 102/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5474 - accuracy: 0.8564 - val_loss: 2.4187 - val_accuracy: 0.6749\n","Epoch 103/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5392 - accuracy: 0.8613 - val_loss: 2.4414 - val_accuracy: 0.6760\n","Epoch 104/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5344 - accuracy: 0.8608 - val_loss: 2.4481 - val_accuracy: 0.6749\n","Epoch 105/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5305 - accuracy: 0.8616 - val_loss: 2.4479 - val_accuracy: 0.6753\n","Epoch 106/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5257 - accuracy: 0.8644 - val_loss: 2.4536 - val_accuracy: 0.6757\n","Epoch 107/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.5228 - accuracy: 0.8642 - val_loss: 2.4586 - val_accuracy: 0.6772\n","Epoch 108/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.5190 - accuracy: 0.8642 - val_loss: 2.4660 - val_accuracy: 0.6764\n","Epoch 109/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.5150 - accuracy: 0.8671 - val_loss: 2.4843 - val_accuracy: 0.6757\n","Epoch 110/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.5086 - accuracy: 0.8677 - val_loss: 2.4792 - val_accuracy: 0.6734\n","Epoch 111/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.5054 - accuracy: 0.8677 - val_loss: 2.4930 - val_accuracy: 0.6772\n","Epoch 112/150\n","48/48 [==============================] - 1s 15ms/step - loss: 0.5018 - accuracy: 0.8685 - val_loss: 2.4912 - val_accuracy: 0.6715\n","Epoch 113/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4958 - accuracy: 0.8697 - val_loss: 2.5028 - val_accuracy: 0.6745\n","Epoch 114/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4932 - accuracy: 0.8704 - val_loss: 2.5057 - val_accuracy: 0.6749\n","Epoch 115/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4876 - accuracy: 0.8723 - val_loss: 2.5233 - val_accuracy: 0.6764\n","Epoch 116/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4850 - accuracy: 0.8739 - val_loss: 2.5227 - val_accuracy: 0.6742\n","Epoch 117/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4806 - accuracy: 0.8727 - val_loss: 2.5350 - val_accuracy: 0.6727\n","Epoch 118/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4748 - accuracy: 0.8742 - val_loss: 2.5302 - val_accuracy: 0.6719\n","Epoch 119/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8775 - val_loss: 2.5345 - val_accuracy: 0.6712\n","Epoch 120/150\n","48/48 [==============================] - 1s 16ms/step - loss: 0.4678 - accuracy: 0.8763 - val_loss: 2.5552 - val_accuracy: 0.6719\n","Epoch 121/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4668 - accuracy: 0.8792 - val_loss: 2.5594 - val_accuracy: 0.6723\n","Epoch 122/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4634 - accuracy: 0.8774 - val_loss: 2.5593 - val_accuracy: 0.6712\n","Epoch 123/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4583 - accuracy: 0.8806 - val_loss: 2.5728 - val_accuracy: 0.6738\n","Epoch 124/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4550 - accuracy: 0.8820 - val_loss: 2.5842 - val_accuracy: 0.6719\n","Epoch 125/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4516 - accuracy: 0.8819 - val_loss: 2.5822 - val_accuracy: 0.6727\n","Epoch 126/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4465 - accuracy: 0.8810 - val_loss: 2.5923 - val_accuracy: 0.6719\n","Epoch 127/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4437 - accuracy: 0.8838 - val_loss: 2.6016 - val_accuracy: 0.6712\n","Epoch 128/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4392 - accuracy: 0.8854 - val_loss: 2.5951 - val_accuracy: 0.6708\n","Epoch 129/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4396 - accuracy: 0.8847 - val_loss: 2.5981 - val_accuracy: 0.6689\n","Epoch 130/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4360 - accuracy: 0.8840 - val_loss: 2.6073 - val_accuracy: 0.6712\n","Epoch 131/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4318 - accuracy: 0.8857 - val_loss: 2.6209 - val_accuracy: 0.6704\n","Epoch 132/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4291 - accuracy: 0.8860 - val_loss: 2.6320 - val_accuracy: 0.6719\n","Epoch 133/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4239 - accuracy: 0.8880 - val_loss: 2.6447 - val_accuracy: 0.6689\n","Epoch 134/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4257 - accuracy: 0.8872 - val_loss: 2.6490 - val_accuracy: 0.6723\n","Epoch 135/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4207 - accuracy: 0.8885 - val_loss: 2.6617 - val_accuracy: 0.6719\n","Epoch 136/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4164 - accuracy: 0.8902 - val_loss: 2.6530 - val_accuracy: 0.6727\n","Epoch 137/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.4148 - accuracy: 0.8894 - val_loss: 2.6628 - val_accuracy: 0.6700\n","Epoch 138/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.4142 - accuracy: 0.8897 - val_loss: 2.6746 - val_accuracy: 0.6723\n","Epoch 139/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4088 - accuracy: 0.8894 - val_loss: 2.6857 - val_accuracy: 0.6704\n","Epoch 140/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4069 - accuracy: 0.8917 - val_loss: 2.6829 - val_accuracy: 0.6723\n","Epoch 141/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4045 - accuracy: 0.8902 - val_loss: 2.6814 - val_accuracy: 0.6697\n","Epoch 142/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.4009 - accuracy: 0.8946 - val_loss: 2.6894 - val_accuracy: 0.6715\n","Epoch 143/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.3976 - accuracy: 0.8935 - val_loss: 2.6985 - val_accuracy: 0.6700\n","Epoch 144/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.3957 - accuracy: 0.8940 - val_loss: 2.7141 - val_accuracy: 0.6738\n","Epoch 145/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.3913 - accuracy: 0.8961 - val_loss: 2.7225 - val_accuracy: 0.6708\n","Epoch 146/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.3931 - accuracy: 0.8952 - val_loss: 2.7328 - val_accuracy: 0.6723\n","Epoch 147/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.3879 - accuracy: 0.8967 - val_loss: 2.7286 - val_accuracy: 0.6704\n","Epoch 148/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.3864 - accuracy: 0.8961 - val_loss: 2.7450 - val_accuracy: 0.6697\n","Epoch 149/150\n","48/48 [==============================] - 1s 13ms/step - loss: 0.3840 - accuracy: 0.8972 - val_loss: 2.7660 - val_accuracy: 0.6730\n","Epoch 150/150\n","48/48 [==============================] - 1s 14ms/step - loss: 0.3811 - accuracy: 0.8996 - val_loss: 2.7502 - val_accuracy: 0.6693\n"]}],"source":["tf.debugging.set_log_device_placement(True)\n","\n","hist = model.fit(\n","    [encoder_input_sequences, decoder_input_sequences],\n","    decoder_targets,\n","    epochs=150,\n","    validation_split=0.2)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist.history['accuracy']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Zbwn0ekDy_s2"},"source":["### 5 - Inferencia\n","Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# Armar los conversores de índice a palabra:\n","idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n","idx2word_target = {v:k for k, v in word2idx_outputs.items()}"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def translate_sentence(input_seq):\n","    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n","    # para enviar la primera vez al decoder\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = word2idx_outputs['<sos>']\n","\n","    # Se obtiene el índice que finaliza la inferencia\n","    eos = word2idx_outputs['<eos>']\n","    \n","    output_sentence = []\n","    for _ in range(max_out_len):\n","        # Predicción del próximo elemento\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","        idx = np.argmax(output_tokens[0, 0, :])\n","\n","        # Si es \"end of sentece <eos>\" se acaba\n","        if eos == idx:\n","            break\n","\n","        # Transformar idx a palabra\n","        word = ''        \n","        if idx > 0:\n","            word = idx2word_target[idx]\n","            output_sentence.append(word)\n","\n","        # Actualizar los estados dada la última predicción\n","        states_value = [h, c]\n","\n","        # Actualizar secuencia de entrada con la salida (re-alimentación)\n","        target_seq[0, 0] = idx\n","\n","    return ' '.join(output_sentence)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","-\n","Input: hey\n","Response: hello how are you\n"]}],"source":["i = np.random.choice(len(input_sentences))\n","input_seq = encoder_input_sequences[i:i+1]\n","translation = translate_sentence(input_seq)\n","print('-')\n","print('Input:', input_sentences[i])\n","print('Response:', translation)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def process_input(input_test):\n","    print('Input:', input_test)\n","    integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n","    print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n","    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n","    print(\"Padding del vector:\", encoder_sequence_test)\n","\n","    print('Input:', input_test)\n","    translation = translate_sentence(encoder_sequence_test)\n","    print('Response:', translation)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: Do you read?\n","Representacion en vector de tokens de ids [9, 2, 12]\n","Padding del vector: [[ 0  0  0  0  9  2 12]]\n","Input: Do you read?\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Response: what do you do\n"]}],"source":["process_input(\"Do you read?\")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: Do you have any pet?\n","Representacion en vector de tokens de ids [9, 2, 24, 107, 347]\n","Padding del vector: [[  0   0   9   2  24 107 347]]\n","Input: Do you have any pet?\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 16ms/step\n","Response: what kind of fish\n"]}],"source":["process_input(\"Do you have any pet?\")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: Where are you from?\n","Representacion en vector de tokens de ids [29, 4, 2, 40]\n","Padding del vector: [[ 0  0  0 29  4  2 40]]\n","Input: Where are you from?\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Response: india\n"]}],"source":["process_input(\"Where are you from?\")"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: Can you speak Chinese?\n","Representacion en vector de tokens de ids [74, 2, 290, 291]\n","Padding del vector: [[  0   0   0  74   2 290 291]]\n","Input: Can you speak Chinese?\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","Response: i love to read\n"]}],"source":["process_input(\"Can you speak Chinese?\")"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: How old are you?\n","Representacion en vector de tokens de ids [8, 48, 4, 2]\n","Padding del vector: [[ 0  0  0  8 48  4  2]]\n","Input: How old are you?\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","Response: i am 32 i am 32\n"]}],"source":["process_input(\"How old are you?\")"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: What do you do for a living?\n","Representacion en vector de tokens de ids [5, 9, 2, 9, 116, 13, 581]\n","Padding del vector: [[  5   9   2   9 116  13 581]]\n","Input: What do you do for a living?\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","Response: talk with me\n"]}],"source":["process_input(\"What do you do for a living?\")"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: What is your name?\n","Representacion en vector de tokens de ids [5, 16, 31, 36]\n","Padding del vector: [[ 0  0  0  5 16 31 36]]\n","Input: What is your name?\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","Response: i am chandan\n"]}],"source":["process_input(\"What is your name?\")"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: Do you have any hobbies?\n","Representacion en vector de tokens de ids [9, 2, 24, 107, 579]\n","Padding del vector: [[  0   0   9   2  24 107 579]]\n","Input: Do you have any hobbies?\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","Response: yes\n"]}],"source":["process_input(\"Do you have any hobbies?\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 6 - Conclusión\n","\n","El modelo obtuvo un buen nivel de accuracy rápidamente durante el entrenamiento y luego se mantuvo estable. En general, las respuestas demostraron ser muy coherentes o se aproximaban a algún concepto relacionado con la respuesta.\n","\n","Si se quisiese mejorar este modelo los proximos pasos serian procesar con todo el dataset o incluso ampliarlo con más muestras. También se podría probar con otros embeddings y con otros hiperparámetros."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
