{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","['de', 'muchas', 'gracias', 'hoy', 'es', 'que', 'el', 'martes', 'dia']\n"]}],"source":["# Prompt ChatGPT con model gpt-4:\n","#\n","# Como precondicion, se tiene el siguiente corpus:\n","# ```\n","# corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","# ```\n","# Se define la siguiente consigna:\n","# ```\n","# ### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","# - Cada documento transformarlo en una lista de términos\n","# - Armar un vector de términos no repetidos de todos los documentos\n","# ```\n","# Dar solucion en codigo python para ser ejecutado en Google Colab\n","\n","# Transformar cada documento en una lista de términos\n","corpus_terms = [doc.split() for doc in corpus]\n","\n","print(corpus_terms)\n","\n","# Aplanar la lista de listas y eliminar términos repetidos\n","vocabulario = list(set([term for sublist in corpus_terms for term in sublist]))\n","\n","print(vocabulario)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Dada una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 0 0 1 1 1 0 0 1]\n"," [1 0 0 1 1 0 1 1 1]\n"," [0 1 1 0 0 0 0 1 0]]\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Realizar una funcion que dada una lista de textos, devolver una matriz con la representación oneHotEncoding de estos, sin utilizar CountVectorizer\n","\n","def one_hot_encoding(corpus):\n","    # Transformar cada documento en una lista de términos\n","    corpus_terms = [doc.split() for doc in corpus]\n","\n","    # Aplanar la lista de listas y eliminar términos repetidos para formar el vocabulario\n","    vocabulario = list(set([term for sublist in corpus_terms for term in sublist]))\n","\n","    # Crear una matriz de ceros con filas igual a la longitud del corpus (número de documentos)\n","    # y columnas igual a la longitud del vocabulario (número de términos únicos)\n","    one_hot_matrix = np.zeros((len(corpus), len(vocabulario)), dtype=int)\n","\n","    # Para cada documento en el corpus\n","    for i, doc in enumerate(corpus_terms):\n","        # Para cada término en el documento\n","        for term in doc:\n","            # Encuentra el índice del término en el vocabulario\n","            j = vocabulario.index(term)\n","            # Coloca un 1 en la posición correspondiente en la matriz\n","            one_hot_matrix[i, j] = 1\n","            \n","    return one_hot_matrix\n","\n","# Probamos la función\n","print(one_hot_encoding(corpus))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Dada una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 0 0 1 1 1 0 0 1]\n"," [1 0 0 1 1 0 1 2 1]\n"," [0 1 1 0 0 0 0 1 0]]\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Siguiendo la misma logica, dada una lista de textos, devolver una matriz con la representación de frecuencia de estos. Sin utilizar la lib de sklearn\n","\n","def term_frequency(corpus):\n","    # Transformar cada documento en una lista de términos\n","    corpus_terms = [doc.split() for doc in corpus]\n","\n","    # Aplanar la lista de listas y eliminar términos repetidos para formar el vocabulario\n","    vocabulario = list(set([term for sublist in corpus_terms for term in sublist]))\n","\n","    # Crear una matriz de ceros con filas igual a la longitud del corpus (número de documentos)\n","    # y columnas igual a la longitud del vocabulario (número de términos únicos)\n","    tf_matrix = np.zeros((len(corpus), len(vocabulario)), dtype=int)\n","\n","    # Para cada documento en el corpus\n","    for i, doc in enumerate(corpus_terms):\n","        # Para cada término en el documento\n","        for term in doc:\n","            # Encuentra el índice del término en el vocabulario\n","            j = vocabulario.index(term)\n","            # Incrementa el contador en la posición correspondiente en la matriz\n","            tf_matrix[i, j] += 1\n","            \n","    return tf_matrix\n","\n","# Probamos la función\n","print(term_frequency(corpus))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Dada una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.         0.         0.         0.40546511 0.40546511 1.09861229\n","  0.         0.         0.40546511]\n"," [1.09861229 0.         0.         0.40546511 0.40546511 0.\n","  1.09861229 0.81093022 0.40546511]\n"," [0.         1.09861229 1.09861229 0.         0.         0.\n","  0.         0.40546511 0.        ]]\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Siguiendo la misma logica, dada una lista de textos, devolver una matriz con la representacion TFIDF sin usar sklearn\n","\n","import math\n","\n","def idf(corpus_terms, vocabulario):\n","    # Crear un vector de ceros con longitud igual a la longitud del vocabulario (número de términos únicos)\n","    idf_vector = np.zeros((len(vocabulario), ))\n","\n","    N = len(corpus_terms)\n","\n","    # Para cada término en el vocabulario\n","    for i, term in enumerate(vocabulario):\n","        # Calcula cuántos documentos contienen el término\n","        df_t = sum([term in doc for doc in corpus_terms])\n","        # Calcula el IDF del término\n","        idf_vector[i] = math.log(N / df_t)\n","        \n","    return idf_vector\n","\n","def tfidf(textos):\n","    # Transformar cada documento en una lista de términos\n","    corpus_terms = [doc.split() for doc in textos]\n","\n","    # Aplanar la lista de listas y eliminar términos repetidos para formar el vocabulario\n","    vocabulario = list(set([term for sublist in corpus_terms for term in sublist]))\n","\n","    # Calcular la matriz de Frecuencia de Término (TF)\n","    tf_matrix = term_frequency(textos)\n","\n","    # Calcular el vector de Frecuencia Inversa de Documento (IDF)\n","    idf_vector = idf(corpus_terms, vocabulario)\n","\n","    # Multiplicar la matriz TF por el vector IDF para obtener la matriz TF-IDF\n","    tfidf_matrix = tf_matrix * idf_vector\n","\n","    return tfidf_matrix\n","\n","\n","# Probamos la función\n","print(tfidf(corpus))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Documento:  que dia es hoy , Documentos ordenados por similitud: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","Documento:  martes el dia de hoy es martes , Documentos ordenados por similitud: ['martes el dia de hoy es martes' 'que dia es hoy' 'martes muchas gracias']\n","Documento:  martes muchas gracias , Documentos ordenados por similitud: ['martes muchas gracias' 'martes el dia de hoy es martes' 'que dia es hoy']\n"]}],"source":["# Continuando chat abierto con ChatGPT:\n","#\n","# Se tiene definida la siguiente funcion:\n","#\n","# ```\n","# def cosine_similarity(a, b):\n","#     return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))\n","# ```\n","#\n","# Se tiene la siguiente consigna:\n","#\n","# ```\n","# ### 5 - Comparación de documentos\n","# Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno\n","# ```\n","\n","def compare_documents(corpus, index):\n","    # Obtener los vectores tf-idf del corpus\n","    vectors = tfidf(corpus)\n","    \n","    # Obtener el vector del documento de interés\n","    doc_vector = vectors[index]\n","    \n","    # Calcular la similitud coseno entre el documento de interés y cada documento en el corpus\n","    similarities = [cosine_similarity(doc_vector, vector) for vector in vectors]\n","    \n","    # Ordenar los índices de los documentos en el corpus por su similitud con el documento de interés\n","    sorted_indices = np.argsort(similarities)[::-1]\n","    \n","    # Devolver los documentos ordenados por similitud\n","    return corpus[sorted_indices]\n","\n","# Probamos la función\n","for i in range(0, len(corpus)):\n","    print( \"Documento: \", corpus[i], \", Documentos ordenados por similitud:\", compare_documents(corpus, i))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
